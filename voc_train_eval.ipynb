{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<h1><div style=\"text-align: center;\"> MSc Artificial Intelligence </div></h1>\n",
    "<h2><div style=\"text-align: center;\"> Object detection and Instance semantic segmentation -\n",
    "Pascal VOC\n",
    "</div></h2>\n",
    "\n",
    "<h3><div style=\"text-align: center;\"> A Ascencio-Cabral\n",
    "</div></h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Models\n",
    "\n",
    "- Faster-RCNN-50-FPN,\n",
    "- Mask-RCNN-50-FPN\n",
    "- Mask-RCNN-101-FPN\n",
    "- Mask-RCNN-101-FPN with customised anchors\n",
    "\n",
    "### Evaluation - Coco style metrics\n",
    " - mean average precision (AP or mAP) at IoU [0.5, 0.05, 0.95], 0.75 and 0.50\n",
    "\n",
    "This code is based on the following tutorials\n",
    "\n",
    "- https://learn-pytorch.oneoffcoder.com/object-detection.html\n",
    "- https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "The folder utility contains code from pytorch with some hacks to track the loss and the average\n",
    "precision per epoch during training and validation.\n",
    "- https://github.com/pytorch/vision/tree/master/references/detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Comment out if pycocotools is not install\n",
    "!pip install cython\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%cd '/content/drive/MyDrive/INM705'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN, MaskRCNNPredictor\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights, \\\n",
    "    maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "from torchvision.models.detection.backbone_utils import _resnet_fpn_extractor, \\\n",
    "    _validate_trainable_layers\n",
    "from torchvision.ops import misc as misc_nn_ops\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead\n",
    "\n",
    "from pascal_dataset import PascalVoc\n",
    "from utility.engine import train_one_epoch, evaluate\n",
    "import utility.utils as utils\n",
    "import utility.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(37)\n",
    "np.random.seed(37)\n",
    "torch.manual_seed(37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Pascal VOC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment to unzip\n",
    "# !unzip './data' -d './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Images:', len(os.listdir('data/Images')))\n",
    "print('Masks:', len(os.listdir('data/GT')))\n",
    "print('Annotations:', len(os.listdir('data/annotations')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Example of a process image with boxes and masks\n",
    "root = os.path.join(os.getcwd(), 'data')\n",
    "dataset = PascalVoc(root, transforms=None)\n",
    "dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.get_img_name(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Maps available devices\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#VOC Classes\n",
    "voc_classes= ('__background__','aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "                           'bus','car','cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
    "                           'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train',\n",
    "                           'tvmonitor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  3.1 Built Mask-RCNN-ResNet-101-FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def maskrcnn_resnet101_fpn(*, progress=True, num_classes=None,\n",
    "    weights_backbone=ResNet101_Weights.IMAGENET1K_V2, trainable_backbone_layers=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Adapted from pytorch maskrcnn_resnet50_fpn\n",
    "    https://pytorch.org/vision/main/_modules/torchvision/models/detection/mask_rcnn.html#maskrcnn_resnet50_fpn\n",
    "    \"\"\"\n",
    "    weights_backbone = ResNet101_Weights.verify(weights_backbone)\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = 91\n",
    "\n",
    "    is_trained = weights_backbone is not None\n",
    "    trainable_backbone_layers = _validate_trainable_layers(is_trained, trainable_backbone_layers, 5, 3)\n",
    "    norm_layer = misc_nn_ops.FrozenBatchNorm2d if is_trained else nn.BatchNorm2d\n",
    "    backbone = resnet101(weights=weights_backbone, progress=progress, norm_layer=norm_layer)\n",
    "    backbone = _resnet_fpn_extractor(backbone, trainable_backbone_layers)\n",
    "    model = MaskRCNN(\n",
    "        backbone,\n",
    "        num_classes=num_classes,\n",
    "        **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Build the segmentation and detection models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's update input features for the predictor and classifier for the models.\n",
    "Masrcnn-Resnet101-FPN requires first to update the state dictionary with the common parameters in\n",
    " the backbone and then create new box and mask predictors for the 21 VOC classes (20 + background).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_instance_segmentation_model(num_classes, backbone, custom_anchors=False, pretrained=True,\n",
    "                                    task='detection'):\n",
    "    \"\"\"\n",
    "    :param num_classes: an integer with the number of classes in the dataset including the\n",
    "    background\n",
    "    :param backbone: string with the name of the backbon eto use\n",
    "    :param custom_anchors: a boolean indicating whether custom anchor should be built\n",
    "    :param pretrained: a boolean to indicate in the model is pretrained\n",
    "    :param task: a boolean indicating whether is a detection or segmentation task - Faster-RCNN\n",
    "    :return:  a deep model\n",
    "    \"\"\"\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "\n",
    "    assert backbone in ['resnet-50-fpn', 'resnet-101-fpn' ], \\\n",
    "        'input one of resnet-50-fpn or resnet-101-fpn'\n",
    "\n",
    "    assert task in ['segmentation', 'detection' ], 'input detection or segmentation'\n",
    "\n",
    "    if backbone == \"resnet-50-fpn\" and task == 'segmentation':\n",
    "\n",
    "        if pretrained:\n",
    "            model = maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "        else:\n",
    "            model = maskrcnn_resnet50_fpn()\n",
    "\n",
    "        # get number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "        # get the number of input features for the mask classifier\n",
    "        in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "        hidden_layer = 256\n",
    "        # and replace the mask predictor with a new one\n",
    "        model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer,\n",
    "                                                           num_classes)\n",
    "        m_name = 'maskrcnn-resnet50-fpn'\n",
    "        print(m_name)\n",
    "\n",
    "    elif backbone == 'resnet-101-fpn' and task == 'segmentation' and custom_anchors:\n",
    "\n",
    "        model = maskrcnn_resnet101_fpn(num_classes=num_classes)\n",
    "\n",
    "        #create a customised anchors for the FPN which by default has 5 outputs\n",
    "        anchor_generator = AnchorGenerator(\n",
    "        sizes=tuple([(16, 32, 64, 128, 256, 512) for _ in range(5)]),\n",
    "        aspect_ratios = tuple([(0.5, 1.0, 2.0) for _ in range(5)]))\n",
    "        model.rpn.anchor_generator = anchor_generator\n",
    "        model.rpn.head = RPNHead(256, anchor_generator.num_anchors_per_location()[0])\n",
    "\n",
    "        # get number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "        # get the number of input features for the mask classifier\n",
    "        in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "        hidden_layer = 256\n",
    "        # replace the mask predictor with a new one\n",
    "        model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer,\n",
    "                                                           num_classes)\n",
    "        m_name = 'maskrcnn-resnet101-fpn-ca'\n",
    "        print(m_name)\n",
    "\n",
    "    elif backbone == 'resnet-101-fpn' and task == 'segmentation' and not custom_anchors:\n",
    "\n",
    "        model = maskrcnn_resnet101_fpn(num_classes=num_classes)\n",
    "        # get the number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one -to prevent size clashes\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "        #get the number of input features for the mask classifier\n",
    "        in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "        hidden_layer = 256\n",
    "        # replace the mask predictor with a new one\n",
    "        model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                          hidden_layer, num_classes)\n",
    "        m_name = 'maskrcnn-resnet101-fpn'\n",
    "        print(m_name)\n",
    "\n",
    "    elif backbone == 'resnet-101-fpn' and task =='detection':\n",
    "        assert task == 'segmentation', 'Input segmentation'\n",
    "\n",
    "    else:\n",
    "        weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "        model = fasterrcnn_resnet50_fpn(weights=weights)\n",
    "        # get number of input features for the classifier\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new one\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "        m_name = 'fasterrcnn-resnet50-fpn'\n",
    "        print(m_name)\n",
    "\n",
    "    return model, m_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = [T.PILToTensor(), T.ConvertImageDtype(dtype=torch.float32)]\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The dataset will be randomly split in three subsets. First a list of random indices will be generated by using a random permutation. The split rations are 80:10:10 for training valdation and test data respectively. The model will be trained and evaluated after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main(kwargs):\n",
    "\n",
    "    print(\"........Starting........\")\n",
    "    device = kwargs['device']\n",
    "    num_classes = kwargs['num_classes']\n",
    "\n",
    "    train_dataset = PascalVoc(data_path, get_transform(train=True))\n",
    "    val_dataset = PascalVoc(data_path, get_transform(train=False))\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    torch.manual_seed(1)\n",
    "    indices = torch.randperm(len(train_dataset)).tolist()\n",
    "    indx = round(len(train_dataset) * 0.80)\n",
    "    test_idx = round(len(train_dataset) * 0.90)\n",
    "    train_set = torch.utils.data.Subset(train_dataset, indices[0:indx])\n",
    "    val_set = torch.utils.data.Subset(val_dataset, indices[indx:test_idx])\n",
    "\n",
    "    # define training and validation data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=2,\n",
    "                    shuffle=True, num_workers=2, collate_fn=utils.collate_fn)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "      val_set, batch_size= 2, shuffle=False, num_workers=2,\n",
    "      collate_fn=utils.collate_fn)\n",
    "\n",
    "    # get the model using our helper function\n",
    "    model, model_name = get_instance_segmentation_model(num_classes, backbone=kwargs['backbone'],\n",
    "                                            custom_anchors=kwargs['anchors'],\n",
    "                                            task=kwargs['task'])\n",
    "\n",
    "    # move model to the right device\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    if kwargs['opt'] == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(params, lr=kwargs['lr'],\n",
    "                                  momentum= kwargs['momentum'], weight_decay=kwargs['w_decay'])\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(params, lr=kwargs['lr'], weight_decay=kwargs['w_decay'])\n",
    "\n",
    "\n",
    "    # learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                        step_size= kwargs['step'], gamma=kwargs['gamma'])\n",
    "\n",
    "    #########################\n",
    "    # Training and validation\n",
    "    ##########################\n",
    "\n",
    "    best_loss = np.inf\n",
    "\n",
    "    train_loss =[]\n",
    "    epochs = kwargs['epochs']\n",
    "    lr = kwargs['lr']\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train for one epoch, printing every 100 iterations\n",
    "        loss, _ = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=100)\n",
    "\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # evaluate on the test dataset\n",
    "        _, _ = evaluate(model, val_loader, device=device)\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "\n",
    "            check_point = {'epoch': epoch +1, 'model': model.state_dict(),\n",
    "                           'optimizer_dict': optimizer.state_dict(),\n",
    "                           'scheduler': lr_scheduler.state_dict()}\n",
    "\n",
    "            torch.save(check_point, os.path.join(output_dir,\n",
    "                                                 f'best-{model_name}-{epochs}-{lr}.pth'))\n",
    "\n",
    "    ##############################\n",
    "    #  Plot loss per epoch during training\n",
    "    ############################\n",
    "    plt.plot(train_loss, label='training')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return indices[test_idx:], model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### 4.2 Hyper-parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparametres\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "output_dir = os.path.join(os.getcwd(), 'weigths')\n",
    "try:\n",
    "    os.makedirs(output_dir, exist_ok=False)\n",
    "    print('Directory successfully created')\n",
    "except OSError as error:\n",
    "    print('Directory already exist')\n",
    "\n",
    "# Select Adam or SGD\n",
    "optims = ['SGD', 'Adam']\n",
    "tasks = ['detection', 'segmentation']\n",
    "backbone_names = ['resnet-50-fpn', 'resnet-101-fpn']\n",
    "params_dict = {'task': tasks[1], 'backbone':backbone_names[1], 'device': device, 'num_classes':\n",
    "    21, 'anchors': True, 'opt': optims[1], 'step': 5, 'gamma':0.5, 'epochs': 20, 'lr': 0.0001,\n",
    "               'w_decay': 0.0001, 'momentum': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run experiment\n",
    "test_ind, net_name = main(params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Build the test dataset and test data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare test dataset\n",
    "voc_dataset = PascalVoc(data_path, get_transform(train=False))\n",
    "test_dataset = torch.utils.data.Subset(voc_dataset, test_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2,\n",
    "  collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_weights = 'fasterrcnn-resnet50-fpn'\n",
    "ep = params_dict['epochs']\n",
    "lr = params_dict['lr']\n",
    "net_name = f'{net_name}-{ep}-{lr}'\n",
    "checkpoint_dir = os.path.join(output_dir, f'best-{net_name}.pth')\n",
    "checkpoint = torch.load(checkpoint_dir, map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Load the trained weights onto the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_, _ = get_instance_segmentation_model(num_classes=params_dict['num_classes'], backbone=params_dict['backbone'],\n",
    "                                            custom_anchors=params_dict['anchors'], task=params_dict['task'])\n",
    "model_.load_state_dict(checkpoint['model'], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Built evaluation fuction per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def map_per_class(coco_evaluator, inst_seg=True):\n",
    "    \"\"\"\n",
    "    Code adapted from\n",
    "    https://github.com/kevalmorabia97/Object-and-Semantic-Part-Detection-pyTorch/blob/master/extra/per_class_AP.ipynb\n",
    "    \"\"\"\n",
    "    d = coco_evaluator.coco_eval['bbox'].eval['precision']\n",
    "    #  All classes except `__background__`\n",
    "    d_classes = d.shape[2]\n",
    "    d_ap_class = [np.mean(d[0, :, cl, 0, 2]) for cl in range(d_classes)]\n",
    "    if inst_seg:\n",
    "        s = coco_evaluator.coco_eval['segm'].eval['precision']\n",
    "        s_classes = s.shape[2]\n",
    "        s_ap_class = [np.mean(s[0, :, cl, 0, 2]) for cl in range(s_classes)]\n",
    "        return d_ap_class, s_ap_class\n",
    "    else:\n",
    "        return d_ap_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def metric_per_class(dataset, coco_evaluator, inst_seg=True, num_classes=21, fname=None,\n",
    "                     metrics_dir=None):\n",
    "\n",
    "    metrics = {}\n",
    "    if inst_seg:\n",
    "        d_ap_class, s_ap_class  = map_per_class(coco_evaluator, inst_seg=True)\n",
    "        for i in range(1, num_classes):\n",
    "            cl = dataset.idx_to_class[i]\n",
    "            det = round(100 * d_ap_class[i-1], 2)\n",
    "            seg = round(100 * s_ap_class[i-1], 2)\n",
    "            print(f'Detection {cl}: {det} | Segmentation {cl}: {seg}')\n",
    "            metrics[cl] = [det, seg]\n",
    "        df = pd.DataFrame.from_dict(metrics)\n",
    "        df.insert(0, 'Model', fname)\n",
    "        df.insert(1, 'Task', ['detection', 'segmentation'])\n",
    "\n",
    "    else:\n",
    "        d_ap_class = map_per_class(coco_evaluator, inst_seg=False)\n",
    "        for i in range(1, num_classes):\n",
    "            cl = dataset.idx_to_class[i]\n",
    "            det = round(100 * d_ap_class[i-1], 2)\n",
    "            print(f'Detection {cl}: {det}')\n",
    "            metrics[cl] = [det]\n",
    "        df = pd.DataFrame.from_dict(metrics)\n",
    "        df.insert(0, 'Model', fname)\n",
    "        df.insert(1, 'Task', ['detection'])\n",
    "\n",
    "    df.to_csv(os.path.join(metrics_dir,  f'{fname}.csv'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = os.path.join(os.getcwd(), 'metrics')\n",
    "try:\n",
    "    os.makedirs(results_dir, exist_ok=False)\n",
    "    print('Directory successfully created')\n",
    "except OSError as error:\n",
    "    print('Directory already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Compute mAP and mAP per class for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "coco_ev, test_stats = evaluate(model_.to(device), test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "segmentation = True if params_dict['task'] == 'segmentation' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metrics_df = metric_per_class(voc_dataset, coco_ev, inst_seg=segmentation, num_classes=21,\n",
    "                              fname=net_name, metrics_dir=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise result \n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  6.1 Color map decoding for masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function allows us to visualize a particular segmentation output, by setting\n",
    "# each pixel color according to the given segmentation class provided in the\n",
    "# image (segmentation output).\n",
    "# Adapted from https://learnopencv.com/pytorch-for-beginners-semantic-segmentation-using\n",
    "# -torchvision/\n",
    "def decode_segmap(image, n_classes=21):\n",
    "\n",
    "    label_colours = [(0, 255, 0), (0, 0, 255), (255, 0, 0), (0, 255, 255), (255, 255, 0),\n",
    "               (0, 128, 128), (255, 0, 2550), (80, 70, 180), (250, 80, 190), (64, 128, 0),\n",
    "               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
    "               (0, 64, 0), (128, 64, 0), (0, 192, 0), (70, 150, 250), (50, 190, 190)]\n",
    "\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    g = np.zeros_like(image).astype(np.uint8)\n",
    "    b = np.zeros_like(image).astype(np.uint8)\n",
    "\n",
    "    r[image == 1], g[image == 1], b[image == 1] = label_colours[random.randrange(0, 20)]\n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "\n",
    "    return rgb, label_colours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Build prediction and inference functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_prediction(pred, threshold, seg=True, msk_thres=0.5):\n",
    "    \"\"\"\n",
    "    :param pred:  dictionary with the prediction\n",
    "    :param threshold: float, threshol for detection\n",
    "    :param seg: boolean, wheter the nference is for a segmentation model or detectection only\n",
    "    :param msk_thres: float threshold for correct ask predictons\n",
    "    :return:  predictions\n",
    "    \"\"\"\n",
    "\n",
    "    pred_score = list(pred['scores'].detach().cpu().numpy())\n",
    "    pred_t = [pred_score.index(s) for s in pred_score if s>threshold][-1]\n",
    "    pred_class = [voc_classes[i] for i in list(pred['labels'].cpu().numpy())]\n",
    "    pred_boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))]\n",
    "                  for i in list(pred['boxes'].detach().cpu().numpy())]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    pred_score = pred_score[:pred_t+1]\n",
    "    if seg:\n",
    "        masks = (pred['masks']>msk_thres).squeeze(1).detach().cpu().numpy()\n",
    "        pred_masks = masks[:pred_t+1]\n",
    "        return pred_masks, pred_boxes, pred_class, pred_score\n",
    "    else:\n",
    "        return pred_boxes, pred_class, pred_score\n",
    "\n",
    "\n",
    "def test_inference(img, pred, threshold=0.5, msk_thres=0.5, rect_th=2, text_size=0.5, text_th=1,\n",
    "                 seg=False):\n",
    "    \"\"\"\n",
    "    :param img: a pil image\n",
    "    :param pred: a tuple with the predictions\n",
    "    :param threshold: float boxes thresholds\n",
    "    :param msk_thres: float mask threshold\n",
    "    :param rect_th: int thicknes of the rectangle\n",
    "    :param text_size: float font size\n",
    "    :param text_th: float the thickness of the test\n",
    "    :param seg: boolean indicates segmentation or only a detection model\n",
    "    :return: the image with the inference\n",
    "    \"\"\"\n",
    "\n",
    "    if seg:\n",
    "        masks, boxes, pred_cls, scores = get_prediction(pred, threshold, seg, msk_thres)\n",
    "        for i in range(len(masks)):\n",
    "            rgb_mask, colors = decode_segmap(masks[i])\n",
    "            img = cv2.addWeighted(np.array(img), 1, rgb_mask, 0.5, 0)\n",
    "            cv2.rectangle(img, boxes[i][0], boxes[i][1], color=(0, 204, 0), thickness=rect_th)\n",
    "            s = str(round(scores[i], 2))\n",
    "            cv2.putText(img, f'{pred_cls[i]}: {s}', (boxes[i][0][0], boxes[i][0][1]-3),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, text_size, color=(0, 204, 0), thickness=text_th,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    else:\n",
    "        boxes, pred_cls, scores = get_prediction(pred, threshold, segmentation, msk_thres)\n",
    "        for i in range(len(boxes)):\n",
    "            cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 204, 0), thickness=rect_th)\n",
    "            s = str(round(scores[i], 2))\n",
    "            cv2.putText(img, f'{pred_cls[i]}: {s}', (boxes[i][0][0], boxes[i][0][1]-3),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, text_size, color=(0, 204, 0), thickness=text_th,\n",
    "                      lineType=cv2.LINE_AA)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_inference(model, loader, threshold=0.7, mask_thres=0.5, seg=True,\n",
    "                     outdir=None, fname=None):\n",
    "    \"\"\"\n",
    "    :param model: model to evaluate\n",
    "    :param loader:  constructor with tensors of the test images and targets\n",
    "    :param threshold: float to select the boxes\n",
    "    :param mask_thres: float to threshold the masks\n",
    "    :param seg: boolean to show only mask or boxes and masks\n",
    "    :param outdir: str directory to save the inference\n",
    "    :param fname: str name to save the inference\n",
    "    :return: save and show predictions and probability scores on the test images\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    model = model\n",
    "    model.eval()\n",
    "\n",
    "    images, targets = next(iter(loader))\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "    for i, image in enumerate(images):\n",
    "        fig.add_subplot(len(images) // 2, 2, i + 1, xticks=[], yticks=[])\n",
    "        img = torchvision.transforms.ToPILImage()(image)\n",
    "        img = test_inference(np.array(img), predictions[i], threshold, msk_thres=mask_thres,\n",
    "                           seg=seg)\n",
    "        img_id = targets[i]['image_id'].item()\n",
    "        name = voc_dataset.get_img_name(img_id)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(name, color='blue', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if outdir is not None:\n",
    "        fname = f'predictions_{fname}.png'\n",
    "        return plt.savefig(os.path.join(outdir, fname), bbox_inches='tight',\n",
    "                            format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 6.3 Inference on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inference_dir = os.path.join(os.getcwd(), 'inference')\n",
    "try:\n",
    "    os.makedirs(inference_dir, exist_ok=False)\n",
    "    print('Directory successfully created')\n",
    "except OSError as error:\n",
    "    print('Directory already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_inference(model_.to('cpu'), test_loader, threshold=0.8, mask_thres=0.5,\n",
    "               seg=segmentation, outdir=inference_dir, fname=f'{net_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
